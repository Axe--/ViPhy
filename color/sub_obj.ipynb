{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Object Ontology (IS-A)\n",
    "\n",
    "We aim to find sub-type candidates for objects, and determine the\n",
    "best candidate when resolving annotation ambiguity in region captions.\n",
    "\n",
    "Given object, find sub-types which end with object name.\n",
    "\n",
    "e.g. ball --> {snowball, baseball, soccer ball}\n",
    "\n",
    "#### Approach\n",
    "\n",
    "For an object (O) & associated candidate set (C), we disambiguate the sub-type,\n",
    "using the Image (I) & Dense Captions (T)\n",
    "\n",
    "e.g. I = 'path-to-img'; T= 'car, road, meter, wheel, ...'; O = meter, C = {thermometer, parking meter}\n",
    "\n",
    "--> parking meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Union\n",
    "from utils import read_json, save_json, sort_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "object2subtypes = read_json('../data/??????')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from models import Image2TextSimilarity, Text2TextSimilarity\n",
    "\n",
    "# Models\n",
    "im2txt = Image2TextSimilarity('cpu')\n",
    "txt2txt = Text2TextSimilarity('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.202778622508049,\n {'metal garbage can': 0.2734043002128601,\n  'metal trashcan': 0.2729678153991699,\n  'metal trash can': 0.26972121000289917,\n  'steel trash can': 0.2647626996040344,\n  'bathroom trashcan': 0.2619898319244385,\n  'garbage can': 0.25501561164855957,\n  'trashcan': 0.24258899688720703,\n  'metal can': 0.21338750422000885,\n  'tin can': 0.2028762251138687,\n  'can': 0.202778622508049,\n  'water can': 0.20134201645851135,\n  'aluminum can': 0.1989527940750122,\n  'soda can': 0.19333428144454956,\n  'beer can': 0.19059841334819794,\n  'paint can': 0.1849059760570526,\n  'drink can': 0.18371596932411194,\n  'coca cola can': 0.17185527086257935,\n  'bull can': 0.1696702390909195,\n  'pepsi can': 0.16818806529045105,\n  'coke can': 0.1628076434135437,\n  'american': 0.15299029648303986,\n  'pecan': 0.15161356329917908,\n  'toucan': 0.14703787863254547,\n  'pelican': 0.1459970772266388,\n  'watering can': 0.1437484323978424,\n  'word american': 0.1397479772567749})"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = 'https://i.ytimg.com/vi/auUaaGHBgok/maxresdefault.jpg'\n",
    "im = requests.get(im, stream=True).raw\n",
    "\n",
    "anchor = 'can'\n",
    "\n",
    "candidates = list(object2subtypes[anchor])\n",
    "\n",
    "res = im2txt.inference(im, anchor, candidates, top_k=10)\n",
    "\n",
    "print(res, '\\n\\n\\n', candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "txt2txt.inference()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO: Incorporate Region-level information\n",
    "\n",
    "We can use bounding boxes to assign unique instances of a class.\n",
    "Use cropped features to select the candidate subtype.\n",
    "\n",
    "### Two-stage approach:\n",
    "\n",
    "#### Image-level Context for Filtering\n",
    "Image (anchor) --> Objects in captions (anchor)\n",
    "\n",
    "#### Region-level Feature for Selection\n",
    "--> Visual BBox ft. (best)\n",
    "\n",
    "If the bbox_area < 224*224, increase the bbox (h,w) about the center.\n",
    "\n",
    "<br><br><br>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Subtype with Image BBoxes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regions = read_json('../VG/regions/r_20k.json')\n",
    "\n",
    "region2subtypes = read_json('?????')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}